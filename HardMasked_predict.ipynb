{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HardMasked_predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "HLcwXFIEMJrF",
        "outputId": "b2250bc0-12e7-4a1e-d208-8afc7df79590"
      },
      "source": [
        "# downgrade pytorch for incompatibility problem\n",
        "!pip install torch==1.7.0"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 24kB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement torch==1.8.0, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses",
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjNgbT0QLSOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a166db3e-192b-4a68-a1ac-932b5c8ce40e"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install seqeval\n",
        "!pip install sentencepiece\n",
        "import sentencepiece as spm\n",
        "\n",
        "from seqeval.metrics import precision_score as seq_precision, recall_score as seq_recall, f1_score as seq_f1\n",
        "from transformers import AutoTokenizer, XLMRobertaModel, XLMRobertaForMaskedLM\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn \n",
        "from torch.nn import functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm.notebook import tqdm\n",
        "from easydict import EasyDict\n",
        "import gc\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from torch.optim import Adam\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23qZr9TjLZJ7"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCIg9rRCLdv0"
      },
      "source": [
        "\n",
        "def num_parameters(parameters):\n",
        "    num = 0\n",
        "    for i in parameters:\n",
        "        num += len(i)\n",
        "    return num\n",
        "class Detector(nn.Module):\n",
        "    def __init__(self, input_dim,output_dim,  embedding_dim, num_layers, hidden_size):\n",
        "\n",
        "        super(Detector, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.embedding_dim  = embedding_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(num_embeddings = self.input_dim, embedding_dim = self.embedding_dim, )\n",
        "        self.LSTM = nn.LSTM(input_size = self.embedding_dim, hidden_size= self.hidden_size, num_layers = self.num_layers, \n",
        "                            batch_first = True, dropout = 0.1, bidirectional = True)\n",
        "        self.linear = nn.Linear(self.hidden_size*2, self.output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        outputs, (h_n, h_c) = self.LSTM(emb)\n",
        "        logits = self.linear(outputs)\n",
        "\n",
        "        p = self.sigmoid(logits)\n",
        "        return p\n",
        "\n",
        "\n",
        "class HardMasked(nn.Module):\n",
        "    def __init__(self, detector, MaskedLM, detector_tokenizer, maskedlm_tokenzier,device ):\n",
        "        super(HardMasked, self).__init__()\n",
        "\n",
        "        self.detector = detector.to(device)\n",
        "        self.MaskedLM = MaskedLM.to(device)\n",
        "        self.detector_tokenizer = detector_tokenizer\n",
        "        self.maskedlm_tokenizer = maskedlm_tokenizer\n",
        "        self.use_device = device\n",
        "\n",
        "\n",
        "    def forward(self, s):\n",
        "        maskedlm_features = self.prepare_input(s)\n",
        "        outputs = MaskedLM(input_ids = torch.tensor([maskedlm_features['input_ids']], dtype = torch.long, device = self.use_device), \n",
        "                            attention_mask = torch.tensor([maskedlm_features['attention_mask']], dtype = torch.long, device = self.use_device) )\n",
        "        logits = outputs['logits'][0]\n",
        "        output_ids = torch.argmax(logits, dim = -1)\n",
        "        final_output = maskedlm_tokenizer.decode(output_ids)\n",
        "        return final_output\n",
        "\n",
        "\n",
        "    def prepare_input(self, s):\n",
        "\n",
        "        detector_input_ids = self.detector_tokenizer.encode(s, out_type = int)\n",
        "        detector_input_pieces = self.detector_tokenizer.id_to_piece(detector_input_ids)\n",
        "        detector_outputs = (self.detector(torch.tensor([detector_input_ids], dtype = torch.long, device = self.use_device))[0].reshape(1,-1) > 0.5).int()[0] \n",
        "\n",
        "        for i in range(1, len(detector_input_pieces)):\n",
        "            if detector_outputs[i] == 1:\n",
        "                detector_input_pieces[i] = ' <mask>'\n",
        "\n",
        "        masked_s = self.detector_tokenizer.decode(detector_input_pieces)\n",
        "        for i in range(5):\n",
        "            masked_s = re.sub(r'<mask>\\s<mask>', '<mask>', masked_s)\n",
        "\n",
        "        maskedlm_features = maskedlm_tokenizer(masked_s)\n",
        "\n",
        "        return maskedlm_features\n",
        "\n",
        "        \n",
        "        "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QS51tQfLdqZ",
        "outputId": "21481c92-d682-4e17-bbf4-7f06d7267ee9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rBeJYKk3Mnt"
      },
      "source": [
        "# Load detector and XLM-R masked language model to create Hard-Masked XLM-R\n",
        "# Change the directories to Detector967.pkl and spm_tokenizer.model \n",
        "\n",
        "detector_path = '/content/drive/MyDrive/nlp_projects/Text_correction/all_data/Detector967.pkl'\n",
        "detector_tokenizer_path = '/content/drive/MyDrive/nlp_projects/Text_correction/spm_tokenizer.model'\n",
        "\n",
        "MaskedLM = XLMRobertaForMaskedLM.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "maskedlm_tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "\n",
        "\n",
        "detector_tokenizer = spm.SentencePieceProcessor(detector_tokenizer_path, )\n",
        "\n",
        "detector = torch.load(detector_path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W3iyChU3tv0"
      },
      "source": [
        "model = HardMasked(detector, MaskedLM, detector_tokenizer, maskedlm_tokenizer, 'cuda')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2DOkTcoL8W7"
      },
      "source": [
        "s = 'Tôi vẫn luôn iu cô ấy với hết tấm lòng của mk'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Kfd-WsExIkOC",
        "outputId": "a768b967-7dd8-4d71-d403-e8d0f54d1eb5"
      },
      "source": [
        "model(s)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<s> Tôi vẫn luôn yêu cô ấy với hết tấm lòng của mình</s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj8O59DHZjot"
      },
      "source": [
        "s = 'Đi theo anh đến mội chân trời'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o2HUfGObNvNS",
        "outputId": "9d7f48d4-6941-4efb-c778-e62dcc05051e"
      },
      "source": [
        "model(s)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<s> Đi theo anh đến tận chân trời</s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}